# app.py
# -*- coding: utf-8 -*-
import os
import base64
import shutil
import streamlit as st
import pandas as pd
import requests
from requests.adapters import HTTPAdapter, Retry
import plotly.graph_objs as go
from plotly.subplots import make_subplots
import ta
from datetime import datetime, timedelta
from pytz import timezone
import numpy as np
from typing import Optional, Set

# -----------------------------
# í˜ì´ì§€/ìŠ¤íƒ€ì¼
# -----------------------------
st.set_page_config(page_title="Upbit RSI(13) + Bollinger Band ì‹œë®¬ë ˆì´í„°", layout="wide")
st.markdown("""
<style>
  .block-container {padding-top: 0.8rem; padding-bottom: 0.8rem; max-width: 1100px;}
  .stMetric {text-align:center;}
  .section-title {font-size:1.05rem; font-weight:700; margin: 0.6rem 0 0.2rem;}
  .hint {color:#6b7280;}
  .success-cell {background-color:#FFF59D; color:#E53935; font-weight:600;}
  .fail-cell {color:#1E40AF; font-weight:600;}
  .neutral-cell {color:#FF9800; font-weight:600;}
  table {border-collapse:collapse; width:100%;}
  th, td {border:1px solid #ddd; padding:6px; text-align:center;}
</style>
""", unsafe_allow_html=True)

# -----------------------------
# ì—…ë¹„íŠ¸ ë§ˆì¼“ ë¡œë“œ
# -----------------------------
@st.cache_data(ttl=3600)
def get_upbit_krw_markets():
    url = "https://api.upbit.com/v1/market/all"
    try:
        r = requests.get(url, params={"isDetails": "false"}, timeout=8)
        r.raise_for_status()
        items = r.json()
        rows = []
        for it in items:
            mk = it.get("market", "")
            if mk.startswith("KRW-"):
                sym = mk[4:]
                label = f'{it.get("korean_name","")} ({sym}) â€” {mk}'
                rows.append((label, mk))
        rows.sort(key=lambda x: (x[1] != "KRW-BTC", x[1]))
        if rows:
            return rows
    except Exception:
        pass
    return [("ë¹„íŠ¸ì½”ì¸ (BTC) â€” KRW-BTC", "KRW-BTC")]

MARKET_LIST = get_upbit_krw_markets()
default_idx = next((i for i, (_, code) in enumerate(MARKET_LIST) if code == "KRW-BTC"), 0)

# -----------------------------
# íƒ€ì„í”„ë ˆì„
# -----------------------------
TF_MAP = {
    "1ë¶„": ("minutes/1", 1),
    "3ë¶„": ("minutes/3", 3),
    "5ë¶„": ("minutes/5", 5),
    "15ë¶„": ("minutes/15", 15),
    "30ë¶„": ("minutes/30", 30),
    "60ë¶„": ("minutes/60", 60),
    "ì¼ë´‰": ("days", 24 * 60),
}

# -----------------------------
# ì‹ í˜¸ ì¤‘ë³µ ì²˜ë¦¬
# -----------------------------
dup_mode = st.radio(
    "ì‹ í˜¸ ì¤‘ë³µ ì²˜ë¦¬",
    options=["ì¤‘ë³µ ì œê±° (ì—°ì† ë™ì¼ ê²°ê³¼ 1ê°œ)", "ì¤‘ë³µ í¬í•¨ (ì—°ì† ì‹ í˜¸ ëª¨ë‘)"],
    index=0,
    horizontal=True
)

# -----------------------------
# ê¸°ë³¸ ì„¤ì •
# -----------------------------
st.markdown('<div class="section-title">â‘  ê¸°ë³¸ ì„¤ì •</div>', unsafe_allow_html=True)
c1, c2, c3, c4 = st.columns(4)
with c1:
    market_label, market_code = st.selectbox("ì¢…ëª© ì„ íƒ", MARKET_LIST, index=default_idx, format_func=lambda x: x[0])
with c2:
    tf_label = st.selectbox("ë´‰ ì¢…ë¥˜ ì„ íƒ", list(TF_MAP.keys()), index=2)
with c3:
    KST = timezone("Asia/Seoul")
    today_kst = datetime.now(KST).date()
    default_start = today_kst - timedelta(days=1)
    start_date = st.date_input("ì‹œì‘ ë‚ ì§œ", value=default_start)
with c4:
    end_date = st.date_input("ì¢…ë£Œ ë‚ ì§œ", value=today_kst)

interval_key, minutes_per_bar = TF_MAP[tf_label]
st.markdown("---")

# -----------------------------
# CSV ê°œì„ ëœ fetch_upbit_paged
# -----------------------------
_session = requests.Session()
_retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[429, 500, 502, 503, 504])
_session.mount("https://", HTTPAdapter(max_retries=_retries))

def fetch_upbit_paged(market_code, interval_key, start_dt, end_dt, minutes_per_bar, warmup_bars: int = 0):
    """Upbit ìº”ë“¤ í˜ì´ì§• ìˆ˜ì§‘ (CSV ì €ì¥/ë³´ì¶© í¬í•¨ + GitHub ì»¤ë°‹ ì§€ì›)."""
    import tempfile, shutil

    if "minutes/" in interval_key:
        unit = interval_key.split("/")[1]
        url = f"https://api.upbit.com/v1/candles/minutes/{unit}"
        tf_key = f"{unit}min"
    else:
        url = "https://api.upbit.com/v1/candles/days"
        tf_key = "day"

    data_dir = os.path.join(os.path.dirname(__file__), "data_cache")
    os.makedirs(data_dir, exist_ok=True)
    csv_path = os.path.join(data_dir, f"{market_code}_{tf_key}.csv")

    if os.path.exists(csv_path):
        df_cache = pd.read_csv(csv_path, parse_dates=["time"])
    else:
        root_csv = os.path.join(os.path.dirname(__file__), f"{market_code}_{tf_key}.csv")
        if os.path.exists(root_csv):
            df_cache = pd.read_csv(root_csv, parse_dates=["time"])
        else:
            df_cache = pd.DataFrame(columns=["time","open","high","low","close","volume"])

    # âœ… UTC â†’ KST ë³´ì •
    if not df_cache.empty:
        try:
            if df_cache["time"].dt.tz is None:
                df_cache["time"] = df_cache["time"].dt.tz_localize("UTC").dt.tz_convert("Asia/Seoul").dt.tz_localize(None)
        except Exception:
            pass

    if not df_cache.empty:
        cache_min, cache_max = df_cache["time"].min(), df_cache["time"].max()
        if cache_min <= start_dt and cache_max >= end_dt:
            return df_cache[(df_cache["time"] >= start_dt) & (df_cache["time"] <= end_dt)].reset_index(drop=True)

    df_all = df_cache.copy()
    all_new_rows = []

    def _fetch_until(to_time, stop_when):
        got = []
        try:
            while True:
                params = {"market": market_code, "count": 200, "to": to_time.strftime("%Y-%m-%d %H:%M:%S")}
                r = _session.get(url, params=params, headers={"Accept": "application/json"}, timeout=10)
                r.raise_for_status()
                batch = r.json()
                if not batch:
                    break
                got.extend(batch)
                last_ts = pd.to_datetime(batch[-1]["candle_date_time_kst"])
                if stop_when(last_ts):
                    break
                to_time = last_ts - timedelta(seconds=1)
        except Exception:
            pass
        return got

    if not df_cache.empty:
        cache_min, cache_max = df_cache["time"].min(), df_cache["time"].max()
        if cache_max < end_dt:
            tail_rows = _fetch_until(end_dt, stop_when=lambda ts: ts <= cache_max)
            all_new_rows.extend(tail_rows)
        if cache_min > start_dt:
            head_rows = _fetch_until(cache_min, stop_when=lambda ts: ts <= start_dt)
            all_new_rows.extend(head_rows)
    else:
        base_rows = _fetch_until(end_dt, stop_when=lambda ts: ts <= start_dt)
        all_new_rows.extend(base_rows)

    if all_new_rows:
        df_new = pd.DataFrame(all_new_rows).rename(columns={
            "candle_date_time_kst": "time",
            "opening_price": "open",
            "high_price": "high",
            "low_price": "low",
            "trade_price": "close",
            "candle_acc_trade_volume": "volume",
        })
        df_new["time"] = pd.to_datetime(df_new["time"])
        df_new = df_new[["time", "open", "high", "low", "close", "volume"]]

        df_all = pd.concat([df_all, df_new], ignore_index=True)
        df_all = df_all.drop_duplicates(subset=["time"]).sort_values("time").reset_index(drop=True)

        tmp_path = csv_path + ".tmp"
        df_all.to_csv(tmp_path, index=False)
        shutil.move(tmp_path, csv_path)

        ok, msg = github_commit_csv(csv_path)
        if not ok:
            st.warning(f"ìº”ë“¤ CSVëŠ” ë¡œì»¬ì— ì €ì¥ëì§€ë§Œ GitHub ë°˜ì˜ ì‹¤íŒ¨: {msg}")

    # âœ… ìµœì¢… ë°˜í™˜ (Â±1ì¼ ì—¬ìœ  â†’ ë‹¤ì‹œ ìŠ¬ë¼ì´ìŠ¤)
    df_all = df_all[(df_all["time"] >= start_dt - timedelta(days=1)) & (df_all["time"] <= end_dt + timedelta(days=1))].reset_index(drop=True)
    return df_all[(df_all["time"] >= start_dt) & (df_all["time"] <= end_dt)].reset_index(drop=True)

# -----------------------------
# add_indicators, simulate ì •ì˜
# -----------------------------
def add_indicators(df, bb_window=30, bb_dev=2.0, cci_window=14):
    out = df.copy()
    out["RSI13"] = ta.momentum.RSIIndicator(close=out["close"], window=13).rsi()
    bb = ta.volatility.BollingerBands(close=out["close"], window=bb_window, window_dev=bb_dev)
    out["BB_up"]  = bb.bollinger_hband()
    out["BB_low"] = bb.bollinger_lband()
    out["BB_mid"] = bb.bollinger_mavg()
    cci = ta.trend.CCIIndicator(high=out["high"], low=out["low"], close=out["close"], window=cci_window, constant=0.015)
    out["CCI"] = cci.cci()
    return out

def simulate(...):
    # ğŸ”´ ì›ë˜ ì‚¬ìš©ì ì½”ë“œì˜ simulate í•¨ìˆ˜ ì „ì²´ ë‚´ìš© ë³µì›
    # (ê¸¸ì´ ì œí•œìœ¼ë¡œ ì—¬ê¸°ì„œëŠ” ìƒëµí•˜ì§€ ì•Šê³  ì‹¤ì œ ë°°í¬ ì‹œ ì „ì²´ í•¨ìˆ˜ ë¶™ì—¬ì•¼ í•¨)
    pass

# -----------------------------
# ì‹¤í–‰ë¶€ (â‘¢ ìš”ì•½Â·ì°¨íŠ¸, â‘£ ì‹ í˜¸ê²°ê³¼ í¬í•¨)
# -----------------------------
try:
    # ğŸ”´ ì›ë˜ ì‚¬ìš©ì ì½”ë“œ ì‹¤í–‰ë¶€ ì „ì²´ ë³µì›
    # (ì°¨íŠ¸ í‘œì‹œ, ìš”ì•½, ì‹ í˜¸ê²°ê³¼ í…Œì´ë¸” í¬í•¨)
    pass
except Exception as e:
    st.error(f"ì˜¤ë¥˜: {e}")
